{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先重整流程，然后再想办法完善数据，比如东财"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# import statsmodels.api as sm\n",
    "import QUANTAXIS as QA\n",
    "import talib as ta\n",
    "import datetime, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [12, 8]\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import & update 60-min data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read non-update data\n",
    "data = pd.read_excel('index_60min.xlsx',index_col=0, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QUANTAXIS>> Selecting the Best Server IP of TDX\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USING DEFAULT STOCK IP\n",
      "USING DEFAULT FUTURE IP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QUANTAXIS>> === The BEST SERVER ===\n",
      " stock_ip 60.191.117.167 future_ip 202.103.36.71\n"
     ]
    }
   ],
   "source": [
    "# update data\n",
    "# set update data date\n",
    "start_update = QA.QA_util_get_next_day(data.index[-1].strftime('%Y-%m-%d'), 1)\n",
    "end_update = QA.QA_util_get_last_day(datetime.datetime.today().strftime('%Y-%m-%d'), 1)\n",
    "\n",
    "# retrieve & adjust cols for concating\n",
    "data_update = QA.QA_fetch_get_index_min('tdx', '000001', start_update, end_update, '60min')\n",
    "data_update = data_update.loc[:,['open', 'close', 'high', 'low', 'vol', 'amount', 'up_count',\n",
    "       'down_count', 'code', 'date', 'date_stamp', 'time_stamp', 'type']]\n",
    "\n",
    "# concat data\n",
    "data = pd.concat([data, data_update], axis=0)\n",
    "\n",
    "# save data\n",
    "writer = pd.ExcelWriter('index_60min.xlsx')\n",
    "data.to_excel(writer)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample data\n",
    "data_min = data[(data.index.hour == 10) | (data.index.hour == 11)].loc[:, \n",
    "    ['open', 'high', 'low', 'close', 'vol', 'amount']]\n",
    "data_min_resample_day = data_min.resample('D').apply({\n",
    "    'open':'first', 'high':'max', 'low':'min', 'close':'last',\n",
    "    'vol':'sum','amount':'sum'\n",
    "}).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QUANTAXIS>> Selecting the Best Server IP of TDX\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USING DEFAULT STOCK IP\n",
      "USING DEFAULT FUTURE IP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QUANTAXIS>> === The BEST SERVER ===\n",
      " stock_ip 60.191.117.167 future_ip 202.103.36.71\n"
     ]
    }
   ],
   "source": [
    "end_update = QA.QA_util_get_last_day(datetime.datetime.today().strftime('%Y-%m-%d'), 1)\n",
    "start = '2016-11-16'\n",
    "end = end_update\n",
    "index_day = QA.QA_fetch_get_index_day('tdx', '000001', start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_data(data, start, end):\n",
    "    \"\"\"\n",
    "    Implements:\n",
    "        update the 60mins data & save the data to the excel file\n",
    "    \n",
    "    Arguments:\n",
    "        data -- dataframe type, 60mins data that to be updating\n",
    "        start -- str, the data updated start date\n",
    "        end -- str, the data updated end date\n",
    "    \n",
    "    Returns:\n",
    "        data\n",
    "    \"\"\"\n",
    "    # retrieve & adjust cols for concating\n",
    "    data_update = QA.QA_fetch_get_index_min('tdx', '000001', start, end, '60min')\n",
    "    data_update = data_update.loc[:,['open', 'close', 'high', 'low', 'vol', 'amount', 'up_count',\n",
    "           'down_count', 'code', 'date', 'date_stamp', 'time_stamp', 'type']]\n",
    "\n",
    "    # concat data\n",
    "    data = pd.concat([data, data_update], axis=0)\n",
    "\n",
    "    # save data\n",
    "    writer = pd.ExcelWriter('index_60min.xlsx')\n",
    "    data.to_excel(writer)\n",
    "    writer.save()\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_and_import_data():\n",
    "    \"\"\"\n",
    "    Implements:\n",
    "        update the 60min data\n",
    "        import the data\n",
    "    \n",
    "    Arguments:\n",
    "        --\n",
    "    \n",
    "    Returns:\n",
    "        data_min_resample_day\n",
    "        index_day\n",
    "    \"\"\"\n",
    "    # read non-update data\n",
    "    data = pd.read_excel('index_60min.xlsx',index_col=0, header=0)\n",
    "    \n",
    "    start_update = QA.QA_util_get_next_day(data.index[-1].strftime('%Y-%m-%d'), 1)\n",
    "    today = datetime.datetime.today().strftime('%Y-%m-%d')\n",
    "    end_update = QA.QA_util_get_last_day(today, 1)\n",
    "    \n",
    "    if start_update < today:\n",
    "        data = update_data(data, start_update, end_update)\n",
    "    \n",
    "    # resample data\n",
    "    data_min = data[(data.index.hour == 10) | (data.index.hour == 11)].loc[:, \n",
    "        ['open', 'high', 'low', 'close', 'vol', 'amount']]\n",
    "    data_min_resample_day = data_min.resample('D').apply({\n",
    "        'open':'first', 'high':'max', 'low':'min', 'close':'last',\n",
    "        'vol':'sum','amount':'sum'\n",
    "    }).dropna()\n",
    "    \n",
    "    start = '2016-11-16'\n",
    "    end = end_update\n",
    "    index_day = QA.QA_fetch_get_index_day('tdx', '000001', start, end)\n",
    "    \n",
    "    return (data_min_resample_day, index_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_right_nums(data_half_day, data_full_day, cur_half_day_range):\n",
    "    \"\"\"\n",
    "    Implements:\n",
    "        依据半天的涨幅，计算出有多少半天的涨幅和全天涨幅一致的数量和整体数量\n",
    "    Arguments:\n",
    "        \n",
    "    Returns:\n",
    "        \n",
    "    \"\"\"\n",
    "    # 计算半天的涨幅和全天的涨幅\n",
    "    half_day_change = (data_half_day.close / data_full_day.close.shift(1))[1:] - 1\n",
    "    full_day_change = data_full_day.close.pct_change()[1:]\n",
    "    \n",
    "    if cur_half_day_range >= 0:\n",
    "        ind = half_day_change >= cur_half_day_range\n",
    "    else:\n",
    "        ind = half_day_change <= cur_half_day_range\n",
    "    \n",
    "    half_filter = half_day_change[ind]\n",
    "    full_filter = full_day_change[ind]\n",
    "    \n",
    "    result = (np.sign(half_filter) * np.sign(full_filter)).value_counts()\n",
    "    right_nums = result.loc[1.0]\n",
    "    total_nums = result.sum()\n",
    "    \n",
    "    return (right_nums, total_nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Kelly_Criterion(p, q, bet_win, bet_loss):\n",
    "    \"\"\"\n",
    "    Implements:\n",
    "        依据当前的半日涨跌幅, 赔率计算仓位\n",
    "    Arguments:\n",
    "        \n",
    "    Returns:\n",
    "        \n",
    "    \"\"\"\n",
    "    f_star = p - q / bet_win\n",
    "    f_star_reverse = q - p / bet_loss\n",
    "    \n",
    "    return (f_star, f_star_reverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_probability_and_position(data_half_day, data_full_day, cur_half_day_range, bet_win, bet_loss):\n",
    "    \"\"\"\n",
    "    Implements:\n",
    "        \n",
    "    Arugments:\n",
    "        \n",
    "    Returns:\n",
    "        \n",
    "    \"\"\"\n",
    "    right_nums, total_nums = calc_right_nums(data_half_day, data_full_day, cur_half_day_range)\n",
    "    if cur_half_day_range >= 0:\n",
    "        p = right_nums / total_nums\n",
    "        q = 1 - p\n",
    "    else:\n",
    "        q = right_nums / total_nums\n",
    "        p = 1 - q\n",
    "        \n",
    "    f_star, f_star_reverse = Kelly_Criterion(p, q, bet_win, bet_loss)\n",
    "    return (f_star, f_star_reverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QUANTAXIS>> Selecting the Best Server IP of TDX\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USING DEFAULT STOCK IP\n",
      "USING DEFAULT FUTURE IP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QUANTAXIS>> === The BEST SERVER ===\n",
      " stock_ip 60.191.117.167 future_ip 202.103.36.71\n"
     ]
    }
   ],
   "source": [
    "data_half_day, data_full_day = update_and_import_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "half_range = 0 * 1e-4\n",
    "bet_win = 0.47\n",
    "bet_loss = 1.72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40863579474342926 -0.2823920265780731\n"
     ]
    }
   ],
   "source": [
    "f_star, f_star_reverse = calc_probability_and_position(data_half_day, data_full_day,\n",
    "                                                       half_range, bet_win, bet_loss)\n",
    "print(f_star, f_star_reverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(f_star * 12000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
